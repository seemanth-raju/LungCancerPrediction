{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seemanth-raju/LungCancerPrediction/blob/main/Welcome_to_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/charlesq34/pointnet.git\n",
        "\n"
      ],
      "metadata": {
        "id": "pcoHP9ftju9Q",
        "outputId": "6505bdb8-0349-4cd4-e37a-cb49e0a99d8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pointnet'...\n",
            "remote: Enumerating objects: 235, done.\u001b[K\n",
            "remote: Total 235 (delta 0), reused 0 (delta 0), pack-reused 235\u001b[K\n",
            "Receiving objects: 100% (235/235), 531.28 KiB | 1.14 MiB/s, done.\n",
            "Resolving deltas: 100% (133/133), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd pointnet\n"
      ],
      "metadata": {
        "id": "YXH-nJaqj1Im",
        "outputId": "7cbd5fb0-a95a-4791-f04b-590c544b3941",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow opencv-python\n"
      ],
      "metadata": {
        "id": "wZEFVidoj29R",
        "outputId": "4fb60fd3-49cb-444e-8706-fffd1d2a3edb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trimesh pygltflib\n"
      ],
      "metadata": {
        "id": "DVGqAl4fkkmH",
        "outputId": "9e16d74e-2804-4552-b1e7-49b0be022886",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: trimesh in /usr/local/lib/python3.10/dist-packages (4.4.3)\n",
            "Requirement already satisfied: pygltflib in /usr/local/lib/python3.10/dist-packages (1.16.2)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from trimesh) (1.26.4)\n",
            "Requirement already satisfied: dataclasses-json>=0.0.25 in /usr/local/lib/python3.10/dist-packages (from pygltflib) (0.6.7)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.10/dist-packages (from pygltflib) (1.2.14)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json>=0.0.25->pygltflib) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json>=0.0.25->pygltflib) (0.9.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->pygltflib) (1.16.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json>=0.0.25->pygltflib) (24.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.0.25->pygltflib) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.0.25->pygltflib) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import trimesh\n",
        "import numpy as np\n",
        "\n",
        "# Load the GLB file as a scene\n",
        "scene = trimesh.load('/content/coco_cola_can.glb')\n",
        "\n",
        "# If the scene contains multiple geometries, you can merge them into a single mesh\n",
        "mesh = trimesh.util.concatenate(scene.dump()) if isinstance(scene, trimesh.Scene) else scene\n",
        "\n",
        "# Sample points from the surface of the mesh\n",
        "point_cloud = mesh.sample(1024)  # Sample 1024 points\n"
      ],
      "metadata": {
        "id": "lrfEazAutq3f"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class PointCloudDataset(Dataset):\n",
        "    def __init__(self, point_cloud, label):\n",
        "        self.point_cloud = point_cloud\n",
        "        self.label = label\n",
        "\n",
        "    def __len__(self):\n",
        "        return 1  # Only one sample\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.point_cloud, dtype=torch.float32), torch.tensor(self.label, dtype=torch.long)\n",
        "\n",
        "# Create dataset and dataloader\n",
        "label = 0  # Assuming '0' is the label for Coca-Cola can\n",
        "dataset = PointCloudDataset(point_cloud, label)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n"
      ],
      "metadata": {
        "id": "96Y0UB8Rt9dc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "class SimplePointNet(nn.Module):\n",
        "    def __init__(self, num_classes=1):\n",
        "        super(SimplePointNet, self).__init__()\n",
        "        self.feature_extractor = resnet18(pretrained=True)\n",
        "        self.feature_extractor.fc = nn.Identity()  # Remove the final classification layer\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Assuming input x is of shape (B, N, 3) where B is batch size and N is the number of points\n",
        "        x = x.permute(0, 2, 1)  # Reshape to (B, 3, N)\n",
        "        x = self.feature_extractor(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate and load the model\n",
        "model = SimplePointNet(num_classes=2)  # Assuming binary classification for now\n",
        "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "xFQhReo5vyNh",
        "outputId": "41b52f9a-6597-4552-b5e6-88b9000aaa3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 185MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "model.train()\n",
        "for epoch in range(10):  # Run for 10 epochs\n",
        "    for points, labels in dataloader:\n",
        "        points, labels = points.to('cuda'), labels.to('cuda')\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(points)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/10], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for points, labels in dataloader:\n",
        "        points, labels = points.to('cuda'), labels.to('cuda')\n",
        "        outputs = model(points)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        print(f'Predicted label: {predicted.item()}, True label: {labels.item()}')\n"
      ],
      "metadata": {
        "id": "H1x0SLo4v2Fr",
        "outputId": "f661f97f-a0c5-43d6-e441-aee1ac101b49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Given groups=1, weight of size [64, 3, 7, 7], expected input[1, 1, 3, 1024] to have 3 channels, but got 1 channels instead",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-f5ae9140179a>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-d7ce4fa1f7d0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Assuming input x is of shape (B, N, 3) where B is batch size and N is the number of points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Reshape to (B, 3, N)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;31m# See note [TorchScript super()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 3, 7, 7], expected input[1, 1, 3, 1024] to have 3 channels, but got 1 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "# PointNet implementation\n",
        "class SimplePointNet(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(SimplePointNet, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(3, 64, 1)\n",
        "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
        "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(2, 1)  # Transpose to shape (B, 3, N)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = torch.max(x, 2, keepdim=True)[0]  # Max pooling\n",
        "        x = x.view(-1, 1024)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Create the dataset class\n",
        "class PointCloudDataset(Dataset):\n",
        "    def __init__(self, point_cloud, label):\n",
        "        self.point_cloud = point_cloud\n",
        "        self.label = label\n",
        "\n",
        "    def __len__(self):\n",
        "        return 1  # Only one sample\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.point_cloud, dtype=torch.float32), torch.tensor(self.label, dtype=torch.long)\n",
        "\n",
        "# Create dataset and dataloader\n",
        "label = 0  # Assuming '0' is the label for Coca-Cola can\n",
        "dataset = PointCloudDataset(point_cloud, label)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# Instantiate and load the model\n",
        "model = SimplePointNet(num_classes=2)  # Assuming binary classification\n",
        "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "Dq_qLv0iv6Ni"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "model.train()\n",
        "for epoch in range(10):  # Run for 10 epochs\n",
        "    for points, labels in dataloader:\n",
        "        points, labels = points.to('cuda'), labels.to('cuda')\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(points)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/10], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for points, labels in dataloader:\n",
        "        points, labels = points.to('cuda'), labels.to('cuda')\n",
        "        outputs = model(points)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        print(f'Predicted label: {predicted.item()}, True label: {labels.item()}')\n"
      ],
      "metadata": {
        "id": "8IYz-JNfwGca",
        "outputId": "c2df5421-5a55-4689-aaf3-8b7d55a07dcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.5933\n",
            "Epoch [2/10], Loss: 0.3440\n",
            "Epoch [3/10], Loss: 0.1428\n",
            "Epoch [4/10], Loss: 0.0267\n",
            "Epoch [5/10], Loss: 0.0035\n",
            "Epoch [6/10], Loss: 0.0008\n",
            "Epoch [7/10], Loss: 0.0000\n",
            "Epoch [8/10], Loss: 0.0000\n",
            "Epoch [9/10], Loss: 0.0000\n",
            "Epoch [10/10], Loss: 0.0000\n",
            "Predicted label: 0, True label: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_point_cloud(file_path):\n",
        "    # Load the GLB file as a scene\n",
        "    scene = trimesh.load(file_path)\n",
        "\n",
        "    # If the scene contains multiple geometries, you can merge them into a single mesh\n",
        "    mesh = trimesh.util.concatenate(scene.dump()) if isinstance(scene, trimesh.Scene) else scene\n",
        "\n",
        "    # Sample points from the surface of the mesh\n",
        "    return mesh.sample(1024)\n",
        "\n",
        "# Assuming you have a list of test file paths and their true labels\n",
        "test_files = ['/content/coco_cola_can.glb', '/content/coca-cola_can__can_of_soda.glb']\n",
        "true_labels = [0, 1]  # Assuming label 0 is for Coca-Cola can, 1 for other objects\n",
        "\n",
        "# Prepare test dataset\n",
        "test_data = [(load_point_cloud(file), label) for file, label in zip(test_files, true_labels)]\n"
      ],
      "metadata": {
        "id": "zUxy1CyDwJBV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for points, true_label in test_data:\n",
        "        points = torch.tensor(points, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
        "        points = points.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        true_label = torch.tensor([true_label], dtype=torch.long).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(points)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total += true_label.size(0)\n",
        "        correct += (predicted == true_label).sum().item()\n",
        "\n",
        "accuracy = correct / total * 100\n",
        "print(f'Accuracy: {accuracy:.2f}%')\n"
      ],
      "metadata": {
        "id": "daKVWgXIwzgx",
        "outputId": "ae5907dc-ebd7-4a2c-e22f-0181fdb49f99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'simple_pointnet_model.pth')\n",
        "print(\"Model saved.\")\n"
      ],
      "metadata": {
        "id": "wUf0SPEow5uX",
        "outputId": "34764a02-065e-4355-f803-c375eaadda73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import trimesh\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Define the PointNet model\n",
        "class SimplePointNet(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(SimplePointNet, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(3, 64, 1)\n",
        "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
        "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(2, 1)  # Transpose to shape (B, 3, N)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = torch.max(x, 2, keepdim=True)[0]  # Max pooling\n",
        "        x = x.view(-1, 1024)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Function to load and sample a point cloud from a GLB file\n",
        "def load_point_cloud(file_path):\n",
        "    # Load the GLB file as a scene\n",
        "    scene = trimesh.load(file_path)\n",
        "\n",
        "    # If the scene contains multiple geometries, merge them into a single mesh\n",
        "    mesh = trimesh.util.concatenate(scene.dump()) if isinstance(scene, trimesh.Scene) else scene\n",
        "\n",
        "    # Sample points from the surface of the mesh\n",
        "    point_cloud = mesh.sample(1024)  # Adjust the number of points as needed\n",
        "    return point_cloud\n",
        "\n",
        "# Function to test the model on a given point cloud file path\n",
        "def test_model(file_path, model, label_mapping):\n",
        "    # Load point cloud\n",
        "    point_cloud = load_point_cloud(file_path)\n",
        "\n",
        "    # Convert point cloud to torch tensor\n",
        "    points = torch.tensor(point_cloud, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
        "    points = points.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Forward pass through the model\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(points)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    # Get the predicted label\n",
        "    predicted_label = label_mapping[predicted.item()]\n",
        "    print(f'Predicted label for {file_path}: {predicted_label}')\n",
        "\n",
        "# Set up the label mapping\n",
        "label_mapping = {0: \"Coke\", 1: \"Unknown\"}\n",
        "\n",
        "# Load the trained model\n",
        "model = SimplePointNet(num_classes=2)  # Adjust num_classes if you have more classes\n",
        "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load the model weights (replace with the actual path to your saved model weights)\n",
        "# model.load_state_dict(torch.load('path/to/model_weights.pth'))\n",
        "\n",
        "# Test the model on new data\n",
        "test_files = ['/content/coco_cola_can.glb']  # Replace with your test file paths\n",
        "model = \"/content/simple_pointnet_model_new.pth\"\n",
        "\n",
        "for file_path in test_files:\n",
        "    test_model(file_path, model, label_mapping)\n"
      ],
      "metadata": {
        "id": "gO-E_ibAxpxm",
        "outputId": "eae88130-5f4d-475a-fb8b-c7a1b9823e48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'eval'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-4fc7fcc08572>\u001b[0m in \u001b[0;36m<cell line: 78>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-33-4fc7fcc08572>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(file_path, model, label_mapping)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# Forward pass through the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'eval'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "finetuning\n"
      ],
      "metadata": {
        "id": "B5iSO250y7QE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import trimesh\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "jeLr-EhSx-BC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PointCloudDataset(Dataset):\n",
        "    def __init__(self, file_paths, labels):\n",
        "        self.file_paths = file_paths\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path = self.file_paths[idx]\n",
        "        scene = trimesh.load(file_path)\n",
        "        mesh = trimesh.util.concatenate(scene.dump()) if isinstance(scene, trimesh.Scene) else scene\n",
        "        point_cloud = mesh.sample(1024)  # Sample 1024 points from the surface\n",
        "        label = self.labels[idx]\n",
        "        return torch.tensor(point_cloud, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "# Example file paths and labels\n",
        "file_paths = ['/content/coco_cola_can.glb', '/content/cokesoda.glb', '/content/coca-cola_can__can_of_soda.glb']  # Add paths to your GLB files\n",
        "labels = [0, 0, 0]  # Assuming all are labeled as 0 (Coca-Cola cans)\n",
        "\n",
        "# Create dataset and dataloader\n",
        "dataset = PointCloudDataset(file_paths, labels)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n"
      ],
      "metadata": {
        "id": "ITHS-fV1zA-n"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimplePointNet(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(SimplePointNet, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(3, 64, 1)\n",
        "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
        "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(2, 1)  # Transpose to shape (B, 3, N)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = torch.max(x, 2, keepdim=True)[0]  # Max pooling\n",
        "        x = x.view(-1, 1024)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "2U_Du3mJzLvK"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate and load the model\n",
        "model = SimplePointNet(num_classes=2)  # Assuming binary classification\n",
        "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "G3xB6sAczPR5"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "model.train()\n",
        "for epoch in range(10):  # Run for 10 epochs\n",
        "    for points, labels in dataloader:\n",
        "        points, labels = points.to('cuda'), labels.to('cuda')\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(points)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/10], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "id": "gwAlFZdOzSXL",
        "outputId": "89b3ab03-eeff-4c8e-a6c8-bb92a2627034",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.1011\n",
            "Epoch [2/10], Loss: 0.0000\n",
            "Epoch [3/10], Loss: 0.0000\n",
            "Epoch [4/10], Loss: 0.0000\n",
            "Epoch [5/10], Loss: 0.0000\n",
            "Epoch [6/10], Loss: 0.0000\n",
            "Epoch [7/10], Loss: 0.0000\n",
            "Epoch [8/10], Loss: 0.0000\n",
            "Epoch [9/10], Loss: 0.0000\n",
            "Epoch [10/10], Loss: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "hbev_U7PzWqb",
        "outputId": "c2cd7e0d-ed01-4d49-d571-b66a1f753469",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimplePointNet(\n",
              "  (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
              "  (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
              "  (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
              "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (fc3): Linear(in_features=256, out_features=2, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    for points, labels in dataloader:\n",
        "        points, labels = points.to('cuda'), labels.to('cuda')\n",
        "        outputs = model(points)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        print(f'Predicted label: {predicted.item()}, True label: {labels.item()}')\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'simple_pointnet_model_new.pth')\n",
        "print(\"Model saved.\")"
      ],
      "metadata": {
        "id": "zkyxjM_bzZE4",
        "outputId": "9efb0ee6-748b-442e-ce44-4c85944f0307",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: 0, True label: 0\n",
            "Predicted label: 0, True label: 0\n",
            "Predicted label: 0, True label: 0\n",
            "Model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import trimesh\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Define the PointNet model class (make sure it matches the one used for training)\n",
        "class SimplePointNet(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(SimplePointNet, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(3, 64, 1)\n",
        "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
        "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(2, 1)  # Transpose to shape (B, 3, N)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = torch.max(x, 2, keepdim=True)[0]  # Max pooling\n",
        "        x = x.view(-1, 1024)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Function to load the model\n",
        "def load_model(model_path):\n",
        "    model = SimplePointNet(num_classes=2)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Function to preprocess the new 3D object\n",
        "def preprocess_3d_object(file_path):\n",
        "    scene = trimesh.load(file_path)\n",
        "    mesh = trimesh.util.concatenate(scene.dump()) if isinstance(scene, trimesh.Scene) else scene\n",
        "    point_cloud = mesh.sample(1024)  # Sample 1024 points from the surface\n",
        "    return torch.tensor(point_cloud, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Function to predict the label of a new 3D object\n",
        "def predict_new_object(model, file_path):\n",
        "    point_cloud = preprocess_3d_object(file_path)\n",
        "    point_cloud = point_cloud.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(point_cloud)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    return predicted.item()\n",
        "# Set up the label mapping\n",
        "label_mapping = {0: \"Coke\", 1: \"Unknown\"}\n",
        "\n",
        "# Load the trained model\n",
        "model_path = 'simple_pointnet_model_new.pth'\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Test the new 3D object\n",
        "new_object_path = '/content/cocacola_bottle.glb'  # Replace with your new GLB file path\n",
        "predicted_label = predict_new_object(model, new_object_path)\n",
        "print(f'Predicted label for the new 3D object: {label_mapping[predicted_label]}')\n"
      ],
      "metadata": {
        "id": "gB0ROXOwzegN",
        "outputId": "4fda7178-fdb0-4079-9250-c3b9ee505e52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label for the new 3D object: Coke\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "color adding"
      ],
      "metadata": {
        "id": "PaAZyVnH1HOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import trimesh\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class PointCloudDatasetWithColor(Dataset):\n",
        "    def __init__(self, file_paths, labels):\n",
        "        self.file_paths = file_paths\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path = self.file_paths[idx]\n",
        "        scene = trimesh.load(file_path)\n",
        "        mesh = trimesh.util.concatenate(scene.dump()) if isinstance(scene, trimesh.Scene) else scene\n",
        "        points = mesh.sample(1024)  # Sample 1024 points\n",
        "        # Retrieve color information\n",
        "        colors = np.zeros((1024, 3))  # Default to black if no colors are available\n",
        "        if hasattr(mesh.visual, 'vertex_colors'):\n",
        "            face_indices = mesh.face_adjacency_angles.sum(axis=1) < trimesh.constants.tol.merge\n",
        "            colors = mesh.visual.face_colors[face_indices[:1024]]\n",
        "        point_cloud = np.hstack((points, colors))  # Combine points and colors\n",
        "        label = self.labels[idx]\n",
        "        return torch.tensor(point_cloud, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "# Example file paths and labels\n",
        "file_paths = ['/content/coco_cola_can.glb']  # Add paths to your GLB files\n",
        "labels = [0, 0, 0]  # Assuming all are labeled as 0 (Coca-Cola cans)\n",
        "\n",
        "# Create dataset and dataloader\n",
        "dataset = PointCloudDatasetWithColor(file_paths, labels)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n"
      ],
      "metadata": {
        "id": "iFiWqgFp1IfI"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SimplePointNetWithColor(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(SimplePointNetWithColor, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(6, 64, 1)  # Input channels changed from 3 to 6\n",
        "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
        "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(2, 1)  # Transpose to shape (B, 6, N)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = torch.max(x, 2, keepdim=True)[0]  # Max pooling\n",
        "        x = x.view(-1, 1024)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate and load the model\n",
        "model = SimplePointNetWithColor(num_classes=2)  # Assuming binary classification\n",
        "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "foDVUXcu1is3"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "model.train()\n",
        "for epoch in range(10):  # Run for 10 epochs\n",
        "    for points, labels in dataloader:\n",
        "        points, labels = points.to('cuda'), labels.to('cuda')\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(points)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/10], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'simple_pointnet_with_color_model.pth')\n",
        "print(\"Model saved.\")\n"
      ],
      "metadata": {
        "id": "Y_U4gNFO1liK",
        "outputId": "7c7eddbe-d989-433b-8307-520df868627e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.7016\n",
            "Epoch [2/10], Loss: 0.4517\n",
            "Epoch [3/10], Loss: 0.2809\n",
            "Epoch [4/10], Loss: 0.0845\n",
            "Epoch [5/10], Loss: 0.0210\n",
            "Epoch [6/10], Loss: 0.0040\n",
            "Epoch [7/10], Loss: 0.0031\n",
            "Epoch [8/10], Loss: 0.0000\n",
            "Epoch [9/10], Loss: 0.0000\n",
            "Epoch [10/10], Loss: 0.0000\n",
            "Model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess the new 3D object with color\n",
        "def preprocess_3d_object_with_color(file_path):\n",
        "    scene = trimesh.load(file_path)\n",
        "    mesh = trimesh.util.concatenate(scene.dump()) if isinstance(scene, trimesh.Scene) else scene\n",
        "    points = mesh.sample(1024)  # Sample 1024 points\n",
        "    # Retrieve color information\n",
        "    colors = np.zeros((1024, 3))  # Default to black if no colors are available\n",
        "    if hasattr(mesh.visual, 'vertex_colors'):\n",
        "        face_indices = mesh.face_adjacency_angles.sum(axis=1) < trimesh.constants.tol.merge\n",
        "        colors = mesh.visual.face_colors[face_indices[:1024]]\n",
        "    point_cloud = np.hstack((points, colors))  # Combine points and colors\n",
        "    return torch.tensor(point_cloud, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Function to load the model\n",
        "def load_model_with_color(model_path):\n",
        "    model = SimplePointNetWithColor(num_classes=2)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Function to predict the label of a new 3D object with color and confidence threshold\n",
        "def predict_new_object_with_confidence(model, file_path, threshold=0.99):\n",
        "    point_cloud = preprocess_3d_object_with_color(file_path)\n",
        "    point_cloud = point_cloud.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(point_cloud)\n",
        "        probabilities = torch.softmax(outputs, dim=1)\n",
        "        confidence, predicted = torch.max(probabilities, 1)\n",
        "\n",
        "    confidence = confidence.item()\n",
        "    predicted_label = predicted.item()\n",
        "\n",
        "    if confidence >= threshold:\n",
        "        return predicted_label, confidence\n",
        "    else:\n",
        "        return 1, confidence\n",
        "\n",
        "# Load the trained model with color support\n",
        "model_path = '/content/simple_pointnet_with_color_model.pth'\n",
        "model = load_model_with_color(model_path)\n",
        "label_mapping = {0: \"Coke\", 1: \"Unknown\"}\n",
        "\n",
        "# Test the new 3D object with color information and confidence threshold\n",
        "new_object_path = '/content/pepsi_can.glb'  # Replace with your new GLB file path\n",
        "predicted_label, confidence = predict_new_object_with_confidence(model, new_object_path)\n",
        "print(f'Predicted label for the new 3D object: label: {label_mapping[predicted_label]}, Confidence: {confidence:.4f}')\n"
      ],
      "metadata": {
        "id": "MtumN9hK1sXU",
        "outputId": "8a8ce218-5385-49c4-b7ad-9d826d717fd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label for the new 3D object: label: Unknown, Confidence: 0.8290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_pmQNtD52KvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dH5wMHhwF3XW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colaboratory",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}